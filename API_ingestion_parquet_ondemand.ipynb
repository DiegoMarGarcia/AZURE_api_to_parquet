{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ec8933-f13a-4b72-a123-fd23df6bd098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Required each time the cluster is restarted which should be only on the first notebook as they run in order \n",
    "tiers = [\"bronze\", \"silver\", \"gold\"]\n",
    "adls_paths = {tier: f\"abfss://{tier}@ibgecase.dfs.core.windows.net/\" for tier in tiers}\n",
    "\n",
    "# Accessing paths \n",
    "bronze_adls = adls_paths [\"bronze\"] \n",
    "silver_adls = adls_paths [\"silver\"] \n",
    "gold_adls = adls_paths[\"gold\"]\n",
    "\n",
    "dbutils.fs.ls (bronze_adls)\n",
    "#dbutils.fs.ls(silver_adls) \n",
    "#dbutils.fs.ls(gold_adls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c91240-1110-459d-b3ba-798a4d06daee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+---------+-------------+----------------------------------------+\n|ano |id |localidade|unidade  |valor        |variavel                                |\n+----+---+----------+---------+-------------+----------------------------------------+\n|2002|37 |Brasil    |Mil Reais|1.488787276E9|Produto Interno Bruto a preços correntes|\n|2003|37 |Brasil    |Mil Reais|1.717950386E9|Produto Interno Bruto a preços correntes|\n|2004|37 |Brasil    |Mil Reais|1.957751224E9|Produto Interno Bruto a preços correntes|\n|2005|37 |Brasil    |Mil Reais|2.170584503E9|Produto Interno Bruto a preços correntes|\n|2006|37 |Brasil    |Mil Reais|2.409449916E9|Produto Interno Bruto a preços correntes|\n|2007|37 |Brasil    |Mil Reais|2.720262951E9|Produto Interno Bruto a preços correntes|\n|2008|37 |Brasil    |Mil Reais|3.109803097E9|Produto Interno Bruto a preços correntes|\n|2009|37 |Brasil    |Mil Reais|3.333039339E9|Produto Interno Bruto a preços correntes|\n|2010|37 |Brasil    |Mil Reais|3.885847E9   |Produto Interno Bruto a preços correntes|\n|2011|37 |Brasil    |Mil Reais|4.376382E9   |Produto Interno Bruto a preços correntes|\n+----+---+----------+---------+-------------+----------------------------------------+\nonly showing top 10 rows\nroot\n |-- ano: long (nullable = true)\n |-- id: string (nullable = true)\n |-- localidade: string (nullable = true)\n |-- unidade: string (nullable = true)\n |-- valor: double (nullable = true)\n |-- variavel: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Criar sessão Spark\n",
    "spark = SparkSession.builder.appName(\"IBGE_PIB\").getOrCreate()\n",
    "\n",
    "# URL oficial IBGE (PIB Municipal)\n",
    "url_pib = \"https://servicodados.ibge.gov.br/api/v3/agregados/5938/periodos/all/variaveis/all?localidades=N1[all]\"\n",
    "url_pop = \"https://servicodados.ibge.gov.br/api/v3/agregados/6579/periodos/all/variaveis/all?localidades=N1[all]\"\n",
    "\n",
    "\n",
    "# Requisição\n",
    "res = requests.get(url_pib)\n",
    "\n",
    "if res.status_code == 200:\n",
    "    data = res.json()\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        var_id = item[\"id\"]\n",
    "        variavel = item[\"variavel\"]\n",
    "        unidade = item[\"unidade\"]\n",
    "\n",
    "        for resultado in item[\"resultados\"]:\n",
    "            for serie in resultado[\"series\"]:\n",
    "                localidade = serie[\"localidade\"][\"nome\"]\n",
    "                for ano, valor in serie[\"serie\"].items():\n",
    "                    rows.append({\n",
    "                        \"id\": var_id,\n",
    "                        \"variavel\": variavel,\n",
    "                        \"unidade\": unidade,\n",
    "                        \"localidade\": localidade,\n",
    "                        \"ano\": int(ano),\n",
    "                        \"valor\": None if valor == \"-\" else float(valor)\n",
    "                    })\n",
    "\n",
    "    # Criar DataFrame Spark\n",
    "    df = spark.createDataFrame(rows)\n",
    "\n",
    "    # Visualizar\n",
    "    df.show(10, truncate=False)\n",
    "    df.printSchema()\n",
    "\n",
    "    #salvando no blob storage\n",
    "    df = df.coalesce(1)  #salva um unico arquivo parquet\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").save(bronze_adls + \"pib_municipal.parquet\")\n",
    "else:\n",
    "    print(f\"Erro {res.status_code}: {res.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10776ab5-8d84-457f-b204-92ada1f9e765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+-------+------------+----------------------------+\n|ano |id  |localidade|unidade|valor       |variavel                    |\n+----+----+----------+-------+------------+----------------------------+\n|2001|9324|Brasil    |Pessoas|1.72385826E8|População residente estimada|\n|2002|9324|Brasil    |Pessoas|1.7463296E8 |População residente estimada|\n|2003|9324|Brasil    |Pessoas|1.76871437E8|População residente estimada|\n|2004|9324|Brasil    |Pessoas|1.81569056E8|População residente estimada|\n|2005|9324|Brasil    |Pessoas|1.84184264E8|População residente estimada|\n|2006|9324|Brasil    |Pessoas|1.86770562E8|População residente estimada|\n|2008|9324|Brasil    |Pessoas|1.89605006E8|População residente estimada|\n|2009|9324|Brasil    |Pessoas|1.9148063E8 |População residente estimada|\n|2011|9324|Brasil    |Pessoas|1.92379287E8|População residente estimada|\n|2012|9324|Brasil    |Pessoas|1.93904015E8|População residente estimada|\n+----+----+----------+-------+------------+----------------------------+\nonly showing top 10 rows\nroot\n |-- ano: long (nullable = true)\n |-- id: string (nullable = true)\n |-- localidade: string (nullable = true)\n |-- unidade: string (nullable = true)\n |-- valor: double (nullable = true)\n |-- variavel: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "url_pop = \"https://servicodados.ibge.gov.br/api/v3/agregados/6579/periodos/all/variaveis/all?localidades=N1[all]\"\n",
    "\n",
    "\n",
    "# Requisição\n",
    "res = requests.get(url_pop)\n",
    "\n",
    "if res.status_code == 200:\n",
    "    data = res.json()\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        var_id = item[\"id\"]\n",
    "        variavel = item[\"variavel\"]\n",
    "        unidade = item[\"unidade\"]\n",
    "\n",
    "        for resultado in item[\"resultados\"]:\n",
    "            for serie in resultado[\"series\"]:\n",
    "                localidade = serie[\"localidade\"][\"nome\"]\n",
    "                for ano, valor in serie[\"serie\"].items():\n",
    "                    rows.append({\n",
    "                        \"id\": var_id,\n",
    "                        \"variavel\": variavel,\n",
    "                        \"unidade\": unidade,\n",
    "                        \"localidade\": localidade,\n",
    "                        \"ano\": int(ano),\n",
    "                        \"valor\": None if valor == \"-\" else float(valor)\n",
    "                    })\n",
    "\n",
    "    # Criar DataFrame Spark\n",
    "    df = spark.createDataFrame(rows)\n",
    "\n",
    "    # Visualizar\n",
    "    df.show(10, truncate=False)\n",
    "    df.printSchema()\n",
    "\n",
    "    #salvando no blob storage\n",
    "    df = df.coalesce(1)  #salva um unico arquivo parquet\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").save(bronze_adls + \"pop_municipal.parquet\")\n",
    "else:\n",
    "    print(f\"Erro {res.status_code}: {res.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "API_ingestion_parquet_ondemand",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}